{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "mount_file_id": "1_3CVgviUQdm3jIa_QwIfP8B7lAbeVj9s",
      "authorship_tag": "ABX9TyOGvebPwLVyZxdEK+tUDgSE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/runtheorun-exe/ir-colab/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrIbqdpgzUrL"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install bert-serving-client\n",
        "!pip install -U bert-serving-server[http]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIWgIimKzalx"
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s20RrpsFzdRs"
      },
      "source": [
        "!unzip uncased_L-12_H-768_A-12.zip\n",
        "!nohup bert-serving-start -model_dir=./uncased_L-12_H-768_A-12 out.file2>&1&"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WohBazyD_66T"
      },
      "source": [
        "from bert_serving.client import BertClient\n",
        "get_ipython().system_raw(\n",
        "'bert-serving-start -model_dir=./uncased_L-12_H-768_A-12 -http_port 3333 &'\n",
        ")\n",
        "import json\n",
        "import requests\n",
        "def get_embeddings(texts):\n",
        "  headers = {'content-type':'application/json'}\n",
        "  data = {\"id\":123,\"texts\":texts,\"is_tokenized\": False}\n",
        "  data = json.dumps(data)\n",
        "  r = requests.post(\"http://localhost:3333/encode\", data=data, headers=headers).json()\n",
        "  return r['result']\n",
        "embedd = get_embeddings(['Hi, How are you doing?'])\n",
        "print(embedd[0])\n",
        "len(embedd[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjhGx70DBA0m"
      },
      "source": [
        "from bert_serving.client import BertClient\n",
        "bc = BertClient()\n",
        "\n",
        "list_text = ['you need to use tensorflow 1', 'tf2 does not work']\n",
        "embedded_text = bc.encode(list_text)\n",
        "\n",
        "print(embedded_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7ikfEV30gAZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "embeddings=embedded_text\n",
        "use= np.array(embeddings).tolist()\n",
        "df=pd.DataFrame()\n",
        "df['vector'] = use\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhXQ4cYq0dCB"
      },
      "source": [
        "len(embedded_text[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0w7HuVL0gH4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel (r'/content/drive/MyDrive/cordis-h2020projects.xlsx')\n",
        "\n",
        "# Or export it in many ways, e.g. a list of tuples\n",
        "tuples = [tuple(x) for x in df.values]\n",
        "\n",
        "# or export it as a list of dicts\n",
        "dicts = df.to_dict().values()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUqbG9Sj2ZYG"
      },
      "source": [
        "list_text=df['objective'].values.tolist()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugMNPbQ3KZBN"
      },
      "source": [
        "embedded_text = bc.encode(list_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFMR1fZGKahU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "embeddings=embedded_text\n",
        "use= np.array(embeddings).tolist()\n",
        "df2=pd.DataFrame()\n",
        "df2['Text_vector'] = use\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbxtQf9MKcdX"
      },
      "source": [
        "result=pd.merge(df, df2, left_index=True, right_index=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnmfkr7rKdZi"
      },
      "source": [
        "result.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY8osT1mzkyx"
      },
      "source": [
        "result.to_csv(\"output.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvPmXfaypb5Z"
      },
      "source": [
        "!pip install elasticsearch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyo0wKrspdII"
      },
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "HOST_URL=[\"http://195.251.166.185:9200\"] #use the ES host URL\n",
        "es=Elasticsearch(HOST_URL)\n",
        "print(es.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ef_WOlcpe9i"
      },
      "source": [
        "request_body = {\n",
        "\"settings\" : {\n",
        "    \"number_of_shards\": 1,\n",
        "    \"number_of_replicas\": 1\n",
        "},\n",
        "\n",
        "\"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"Title\": {\"type\": \"text\"},\n",
        "            \"Text\": {\"type\":  \"text\"},\n",
        "            \"Category\": {\"type\": \"text\"},\n",
        "            \"Text_vector\": {\"type\":  \"dense_vector\", \"dims\":  768}\n",
        "        }}\n",
        "}\n",
        "es.indices.create(index = 'manolis_bert_es_ir_imdb', body = request_body)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOy5e9_U-Tt0"
      },
      "source": [
        "import pandas as pd\n",
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch.helpers import bulk\n",
        "#result.head()\n",
        "documents = result.to_dict(orient='records')\n",
        "#check the first document to see if it's ok\n",
        "print(documents[1])\n",
        "bulk(es,documents,index='cordish2020')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO0E5f0vp4JA"
      },
      "source": [
        "query = 'Title:an artist who was crippled with cerebral palsy and learned to paint with his left foot OR Text:an artist who was crippled with cerebral palsy and learned to paint with his left foot'\n",
        "\n",
        "response= es.search(index='cordish2020',body={\n",
        "  \"query\": {\n",
        "    \"query_string\": {\n",
        "      \"default_field\": \"content\",\n",
        "      \"query\": query    }\n",
        "  }\n",
        "})\n",
        "print(response)\n",
        "print(\"Got %d Hits:\" % response['hits']['total']['value'])\n",
        "print(\"Got %f MaxScore:\" % response['hits']['max_score'])\n",
        "for hit in response['hits']['hits']:\n",
        "    print(\"Score %2.3f:\" %hit[\"_score\"], \"%(Title)s\" % hit[\"_source\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmcvpS56p8Wd"
      },
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "from bert_serving.client import BertClient\n",
        "from elasticsearch.exceptions import ConnectionError, NotFoundError\n",
        "\n",
        "# total number of responses\n",
        "SEARCH_SIZE = 10\n",
        "\n",
        "# establishing connections\n",
        "bc = BertClient(ip='localhost', output_fmt='list', check_length=False)\n",
        "client = Elasticsearch('195.251.166.185:9200')\n",
        "\n",
        "# this query is used as the search term, feel free to change\n",
        "query = 'an artist who was crippled with cerebral palsy and learned to paint with his left foot'\n",
        "query_vector = bc.encode([query])[0]\n",
        "print(query_vector)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjZHaiirp-Fg"
      },
      "source": [
        "script_query = {\n",
        "    \"script_score\": {\n",
        "        \"query\": {\"match_all\": {}},\n",
        "        \"script\": {\n",
        "            \"source\": \"cosineSimilarity(params.query_vector, 'Text_vector') + 1.0\",\n",
        "            \"params\": {\"query_vector\": query_vector}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = client.search(\n",
        "         index='manolis_bert_es_ir_imdb',  # name of the index\n",
        "         body={\n",
        "             \"size\": SEARCH_SIZE,\n",
        "             \"query\": script_query,\n",
        "             \"_source\": {\"includes\": [\"Title\", \"Text\"]}\n",
        "         }\n",
        "     )\n",
        "    #print(response)\n",
        "    #result = [a['_source']['Title'] for a in response['hits']['hits']]\n",
        "    #print(result)\n",
        "    print(\"Got %d Hits:\" % response['hits']['total']['value'])\n",
        "    print(\"Got %f MaxScore:\" % response['hits']['max_score'])\n",
        "    for hit in response['hits']['hits']:\n",
        "      print(\"Score %2.3f:\" %hit[\"_score\"], \"%(Title)s\" % hit[\"_source\"])\n",
        "except ConnectionError:\n",
        "    print(\"[WARNING] docker isn't up and running!\")\n",
        "except NotFoundError:\n",
        "    print(\"[WARNING] no such index!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}